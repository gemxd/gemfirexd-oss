apply plugin: 'wrapper'

buildscript {
  repositories {
    maven { url "https://plugins.gradle.org/m2" }
    jcenter()
  }
  dependencies {
    classpath 'com.github.jengelman.gradle.plugins:shadow:1.2.3'
  }
}

allprojects {
  // We want to see all test results.  This is equivalent to setting --continue
  // on the command line.
  gradle.startParameter.continueOnFailure = true

  repositories {
    jcenter()
    maven { url 'http://repo.spring.io/release' }
    maven { url 'http://repo.spring.io/milestone' }
    maven { url 'http://repo.spring.io/snapshot' }
    maven { url 'http://repo.spring.io/libs-release' }
    maven { url 'http://repo.spring.io/ext-release-local' }
    maven { url 'https://dl.bintray.com/big-data/maven' }
    mavenLocal()
  }

  gradle.taskGraph.whenReady( { graph ->
    tasks.withType(Tar).each { tar ->
      tar.compression = Compression.GZIP
      tar.extension = 'tar.gz'
    }
  })

  ext {
    scalaBinaryVersion = '2.10'
    scalaVersion = scalaBinaryVersion + '.6'
    springVersion = '3.2.12.RELEASE'
    log4jVersion = '1.2.17'
    slf4jVersion = '1.7.12'
    junitVersion = '4.11'
    antVersion = '1.8.4'
    pxfVersion = '2.5.1.0'
    osgiVersion = '6.0.0'
    jettyVersion = '8.1.14.v20131031'
    hadoopVersion = '2.4.1'
    protobufVersion = '2.6.1'
    jerseyVersion = '1.9'
    hadoopJettyVersion = '6.1.26'
    jsr305Version = '1.3.9'
    hbaseVersion = '0.98.17-hadoop2'
    derbyVersion = '10.10.2.0'
    //hbaseVersion = '0.94.4-gemfire-r45047'
    //hadoopVersion = '2.2.0-gphd-3.1.0.0'
    //hadoopVersion = '2.4.1-gphd-3.2.0.0-54'

    // product and release properties
    PRODUCT_NAME = 'SnappyData'

    GEMFIRE_PRODUCT = 'Pivotal GemFire'
    GEMFIRE_VERSION = '7.5.Beta'
    DERBY_NAME = 'Apache Derby'
    DERBY_MAJOR = '10'
    DERBY_MINOR = '4'
    DERBY_MAINT = '2000000'
    DERBY_DRDA_MAINT = '1'

    PRODUCT_MAJOR = '1'
    PRODUCT_MINOR = '5'
    PRODUCT_MAINT = '0'
    PRODUCT_CLASSFIER = '-BETA2'
    PRODUCT_VERSION = "${PRODUCT_MAJOR}.${PRODUCT_MINOR}.${PRODUCT_MAINT}${PRODUCT_CLASSFIER}"
    PRODUCT_VENDOR = 'SnappyData, Inc.'
    COPYRIGHT = "Copyright 2016, ${PRODUCT_VENDOR} All rights reserved."

    if (rootProject.name == 'snappy-store') {
      subprojectBase = ':'
      gitCmd = "git --git-dir=${rootDir}/.git --work-tree=${rootDir}"
    } else {
      subprojectBase = ':snappy-store:'
      gitCmd = "git --git-dir=${project(':snappy-store').projectDir}/.git --work-tree=${project(':snappy-store').projectDir}"
    }

    gitBranch = "${gitCmd} rev-parse --abbrev-ref HEAD".execute().text.trim()
    commitId = "${gitCmd} rev-parse HEAD".execute().text.trim()
    sourceDate = "${gitCmd} log -n 1 --format=%ai".execute().text.trim()

    osArch = System.getProperty('os.arch')
    osName = org.gradle.internal.os.OperatingSystem.current()
    osVersion = System.getProperty('os.version')
    buildDate = new Date().format('yyyy-MM-dd HH:mm:ss Z')
    buildNumber = new Date().format('MMddyy')
    jdkVersion = System.getProperty('java.version')

    derbyProps = [ 'gemfirexd.version.major': DERBY_MAJOR,
        'gemfirexd.version.minor': DERBY_MINOR,
        'gemfirexd.version.maint': DERBY_MAINT,
        'gemfirexd.version.drdamaint': DERBY_DRDA_MAINT,
        'gemfirexd.build.number': '1',
        'gemfirexd.product.external.name': DERBY_NAME,
        'gemfirexd.product.external.version': "${DERBY_MAJOR}.${DERBY_MINOR}.${DERBY_MAINT}",
        'gemfirexd.version.beta': 'true',
        'gemfirexd.product.vendor': PRODUCT_VENDOR,
        'gemfirexd.product.file': 'gemfirexd.jar' ]
  }

  buildRoot = buildRoot.trim()
  def osDir = osName.getFamilyName().replace(" ", "").toLowerCase()
  if (!buildRoot.isEmpty()) {
    buildDir = new File(buildRoot, osDir + '/' +  project.path.replace(':', '/'))
  } else {
    buildDir = 'build-artifacts/' + osDir
  }

  ext {
    productDir = file("${rootProject.buildDir}/store")
    locDir = 'com/pivotal/gemfirexd/internal/loc'
    clientMsgOutDir = "${project(subprojectBase + 'gemfirexd-core').buildDir}/client/${locDir}"
    if (!project.hasProperty("sanity")) {
      isSane = 'true'
    } else {
      isSane = sanity
    }

    if (rootProject.name == 'snappy-store') {
      testResultsBase = "${rootProject.buildDir}/tests"
    } else {
      testResultsBase = "${rootProject.buildDir}/tests/store"
    }
  }

  group = 'io.snappydata'
  version = PRODUCT_VERSION

  apply plugin: 'java'
  apply plugin: 'maven'
  apply plugin: 'idea'
  apply plugin: 'eclipse'
}

def writeProperties(def parent, def name, def comment, def propsMap) {
  parent.exists() || parent.mkdirs()
  def writer = new File(parent, name).newWriter()
  def props = new Properties()
  propsMap.each { k, v -> props.setProperty(k, v.toString()) }
  try {
    props.store(writer, comment.toString())
    writer.flush()
  } finally {
    writer.close()
  }
}

def writeTestProperties(def parent, def name) {
  def availablePortFinder = AvailablePortFinder.createPrivate()
  writeProperties(new File(parent, name), 'gemfire.properties',
      'Autogenerated Gemfire properties', [
      'mcast-port': Integer.toString(availablePortFinder.nextAvailable),
      'log-level': 'config' ])
}

def getManifest(def symname, def imports, def exports, def otherAttrs) {
  def attrs = [
    "Manifest-Version"        : "1.0",
    "Title"                   : PRODUCT_NAME,
    "Bundle-Name"             : "${PRODUCT_NAME} ${PRODUCT_VERSION}",
    "Bundle-Version"          : PRODUCT_VERSION,
    "Bundle-Vendor"           : PRODUCT_VENDOR,
    "Bundle-SymbolicName"     : symname,
    "Bundle-ActivationPolicy" : "lazy",
    "Bundle-NativeCode"       : "com/sun/jna/win32-x86/jnidispatch.dll; processor=x86;osname=win32, com/sun/jna/win32-x86-64/jnidispatch.dll; processor=x86-64;osname=win32, com/sun/jna/w32ce-arm/jnidispatch.dll; processor=arm;osname=wince,  com/sun/jna/sunos-x86/libjnidispatch.so; processor=x86;osname=sunos, com/sun/jna/sunos-x86-64/libjnidispatch.so; processor=x86-64;osname=sunos, com/sun/jna/sunos-sparc/libjnidispatch.so; processor=sparc;osname=sunos, com/sun/jna/sunos-sparcv9/libjnidispatch.so; processor=sparcv9;osname=sunos,  com/sun/jna/aix-ppc/libjnidispatch.a; processor=ppc;osname=aix, com/sun/jna/aix-ppc64/libjnidispatch.a; processor=ppc64;osname=aix,  com/sun/jna/linux-ppc/libjnidispatch.so; processor=ppc;osname=linux, com/sun/jna/linux-ppc64/libjnidispatch.so; processor=ppc64;osname=linux, com/sun/jna/linux-x86/libjnidispatch.so; processor=x86;osname=linux, com/sun/jna/linux-x86-64/libjnidispatch.so; processor=x86-64;osname=linux, com/sun/jna/linux-arm/libjnidispatch.so; processor=arm;osname=linux, com/sun/jna/linux-ia64/libjnidispatch.so; processor=ia64;osname=linux,  com/sun/jna/freebsd-x86/libjnidispatch.so; processor=x86;osname=freebsd, com/sun/jna/freebsd-x86-64/libjnidispatch.so; processor=x86-64;osname=freebsd, com/sun/jna/openbsd-x86/libjnidispatch.so; processor=x86;osname=openbsd, com/sun/jna/openbsd-x86-64/libjnidispatch.so; processor=x86-64;osname=openbsd,  com/sun/jna/darwin/libjnidispatch.jnilib; osname=macosx;processor=x86;processor=x86-64;processor=ppc",
    "DynamicImport-Package"   : imports,
    "Export-Package"          : exports
  ]
  attrs.putAll(otherAttrs)
  return attrs
}

def generateCommonManifest(def pdir, def bdir) {
  def ddir = "${bdir}/resources/main/META-INF/"
  def fdir = new File(ddir)
  fdir.exists() || fdir.mkdirs()
  copy {
    from "${pdir}/.."
    into ddir
    include 'LICENSE*'
    include 'NOTICE*'
  }
}

def replaceRegex(def fileDir, def fileName, def regex, def replacement) {
  def tmpDir = "${buildDir}/tmp"
  def filePath = "${fileDir}/${fileName}"
  copy {
    from filePath
    into tmpDir
    filter { line ->
      line.replaceAll(regex, replacement)
    }
  }
  file("${tmpDir}/${fileName}").renameTo(file(filePath))
}

def getProcessId() {
  def name = java.lang.mangement.ManagementFactory.getRuntimeMXBean().getName()
  return name[0..name.indexOf("@") - 1]
}

def getStackTrace(def t) {
  java.io.StringWriter sw = new java.io.StringWriter()
  java.io.PrintWriter pw = new java.io.PrintWriter(sw)
  org.codehaus.groovy.runtime.StackTraceUtils.sanitize(t).printStackTrace(pw)
  return sw.toString()
}

task cleanTestOutput << {
  def testDir = "${testResultsBase}/junit"
  delete testDir
  file(testDir).mkdirs()
}
task cleanDUnitOutput << {
  def testDir = "${testResultsBase}/dunit"
  delete testDir
  file(testDir).mkdirs()
  // writeTestProperties(testDir, '.')
}
task cleanWanOutput << {
  def testDir = "${testResultsBase}/wan"
  delete testDir
  file(testDir).mkdirs()
}
task cleanIntegrationOutput << {
  def testDir = "${testResultsBase}/integration"
  delete testDir
  file(testDir).mkdirs()
}
task cleanReports << {
  def reportsDir = "${testResultsBase}/combined-reports"
  delete reportsDir
  file(reportsDir).mkdirs()
}


def parallelTests(def proj, def testClasses, def testObj, def prefix, def splitSize, def parallelism) {
  proj.task("${prefix}Parallel") {
    dependsOn proj.testClasses, "${subprojectBase}product"
    def ntestClasses = testClasses.size()
    def testClassesGroups = testClasses.collate(splitSize)
    def ntestClassesGroups = testClassesGroups.size()
    def lastTestClass = new ThreadLocal<String>()
    def testCount = new java.util.concurrent.atomic.AtomicInteger(0)
    def failureCount = new java.util.concurrent.atomic.AtomicInteger(0)
    def testTasks = (0..<ntestClassesGroups).collect { index ->
      proj.task("${prefix}Parallel${index}", type: Test) {
        maxParallelForks = 1
        minHeapSize = testObj.minHeapSize
        maxHeapSize = testObj.maxHeapSize

        def baseURI = getTestClassesDir().toURI()
        include testClassesGroups[index].collect {
          baseURI.relativize(it.toURI()).getPath()
        }

        workingDir = testObj.workingDir
        binResultsDir = file("${testObj.binResultsDir}_${index}")
        reports.html.enabled = false
        reports.junitXml.destination = file(workingDir)

        systemProperties testObj.systemProperties

        beforeTest { desc ->
          def lastClass = lastTestClass.get()
          if (desc.className != lastClass) {
            def count = testCount.incrementAndGet()
            def now = new Date().format('yyyy-MM-dd HH:mm:ss.SSS Z')
            def threadId = Long.toHexString(Thread.currentThread().getId())
            if (lastClass != null) {
              println "$now <0x$threadId> END $lastClass"
            }
            println "$now <0x$threadId> Start ${desc.className} ($count/$ntestClasses)"
            lastTestClass.set(desc.className)
          }
        }
        afterTest { desc, result ->
          if (result.exceptions.size() > 0) {
            failureCount.incrementAndGet()
          }
        }
      }
    }
    doLast {
      if (ntestClasses > 0) {
        def count = new java.util.concurrent.atomic.AtomicInteger(0)
        def threadProcess = new Runnable() {
          @Override
          void run() {
            def index = 0
            def thread = Thread.currentThread()
            while ((index = count.getAndIncrement()) < ntestClassesGroups) {
              def now = new Date().format('yyyy-MM-dd HH:mm:ss.SSS Z')
              def threadId = Long.toHexString(Thread.currentThread().getId())
              def test = testTasks[index]
              println "$now <0x$threadId> STARTING tests: ${test.getIncludes()}"
              try {
                test.executeTests()
                def lastClass = lastTestClass.get()
                if (lastClass != null) {
                  println "$now <0x$threadId> END $lastClass"
                }
              } catch (Exception e) {
                print "Exception in thread '${thread.getName()}' $e "
                e.printStackTrace()
              }
              now = new Date().format('yyyy-MM-dd HH:mm:ss.SSS Z')
              println "$now <0x$threadId> ENDED tests: ${test.getIncludes()}"
            }
          }
        }
        def threads = new Thread[parallelism]
        parallelism.times { threads[it] = new Thread(threadProcess) }
        threads.each { it.start() }
        threads.each { it.join() }

        def progressTxt = file("${testObj.workingDir}/progress.txt").getAbsolutePath().toURI()
        def report = file("${testObj.workingDir}/html/${proj.name}/index.html").getAbsolutePath().toURI()
        if (failureCount.get() > 0) {
          println()
          def failureMsg = "FAILED: There were ${failureCount.get()} failures.\n"
          failureMsg    += "        See the progress report in: file://$progressTxt\n"
          failureMsg    += "        HTML report in: file://$report"
          throw new GradleException(failureMsg)
        } else {
          println()
          println("SUCCESS: See the progress report in: file://$progressTxt")
          println("         HTML report in: file://$report")
          println()
        }
      }
    }
  }
}


subprojects {
  // apply compiler options
  compileJava.options.encoding = 'UTF-8'

  javadoc {
    options {
      charSet = 'UTF-8'
      windowTitle = 'GemFire XD Java API Documentation'
      docTitle = "<h1>GemFire XD ${project.version} Java API</h1>"
      header = "<i>GemFire XD ${project.version}</i>"
      bottom = '<i>Copyright &copy; 2010-2015 Pivotal Software, Inc. All rights reserved.</i>'
      use = true
      links = [ 'http://docs.oracle.com/javase/7/docs/api/' ]
      verbose = true
    }
  }

  configurations {
    provided {
      description 'a dependency that is provided externally at runtime'
      visible true
    }

    testOutput {
      extendsFrom testCompile
      description 'a dependency that exposes test artifacts'
    }
  }

  // Here we want to disable all transitive dependencies on external artifacts.  This
  // allows us to lock down library versions.  However, we want project dependencies to
  // be transitive such that the libraries of a dependent project are automatically included.
  configurations.all {
    dependencies.all { dep ->
      if (dep instanceof ModuleDependency && !(dep instanceof ProjectDependency)) {
        dep.transitive = false
      }
    }
    resolutionStrategy {
      // fail eagerly on version conflict (includes transitive dependencies)
      // e.g. multiple different versions of the same dependency (group and name are equal)
      failOnVersionConflict()
    }
  }

  eclipse {
    classpath {
      defaultOutputDir = file('build-eclipse')
      plusConfigurations += [ configurations.provided ]     
    }
    // Several files have UTF-8 encoding and Eclipse running on Windows
    // will have trouble unless we tell it to use UTF-8 encoding.
    // This setting needs to go into the core.resources.prefs file,
    // which the JDT script isn't set up to configure
    eclipseJdt << {
      File f = file('.settings/org.eclipse.core.resources.prefs')
      f.write('eclipse.preferences.version=1\n')
      f.append('encoding/<project>=utf-8')
    }
  }

  cleanEclipse << {
    delete '.settings/org.eclipse.core.resources.prefs'
  }

  idea {
    module {
      scopes.PROVIDED.plus += [ configurations.provided ]
    }
  }

  sourceSets {
    main.compileClasspath += configurations.provided
    main.runtimeClasspath -= configurations.provided
    test.compileClasspath += configurations.provided
    test.runtimeClasspath += configurations.provided
  }

  javadoc.classpath += configurations.provided

  dependencies {
    compile 'com.google.code.findbugs:annotations:3.0.0'
    compile "log4j:log4j:${log4jVersion}"
    compile "org.slf4j:slf4j-api:${slf4jVersion}"
    compile "org.slf4j:slf4j-log4j12:${slf4jVersion}"

    testCompile "junit:junit:${junitVersion}"
    testCompile 'org.hamcrest:hamcrest-core:1.3'
    testCompile 'org.hamcrest:hamcrest-library:1.3'
    testCompile 'org.jmock:jmock:2.5.1'
    testCompile 'org.jmock:jmock-legacy:2.5.1'
    testCompile 'edu.umd.cs.mtc:multithreadedtc:1.01'
    testRuntime 'cglib:cglib-nodep:2.1_3'
    testRuntime 'org.objenesis:objenesis:1.0'
  }

  test {
    dependsOn "${subprojectBase}product"
    maxParallelForks = (2 * Runtime.getRuntime().availableProcessors())
    minHeapSize = '768m'
    maxHeapSize = '768m'

    def single = System.getProperty("junit.single")
    if (single == null || single.length() == 0) {
      include '**/*Test.class'
      exclude '**/*DUnitTest.class'
      exclude '**/*DUnit.class'
      exclude '**/derbyTesting/**'
    } else {
      include single
    }

    useJUnit {
      excludeCategories 'com.gemstone.junit.IntegrationTest'
      excludeCategories 'com.gemstone.junit.DistributedTest'
    }

    workingDir = "${testResultsBase}/junit"

    binResultsDir = file("${workingDir}/binary/${project.name}")
    reports.html.destination = file("${workingDir}/html/${project.name}")
    reports.junitXml.destination = file(workingDir)
  }
  task junitSingle1(type: Test) {
    def single = System.getProperty("junit.single")
    if (single == null || single.length() == 0) {
      include '**/BugsTest.class'
      include '**/DDLPersistenceHDFSTest.class'
    } else {
      include single
    }
  }
  task junitSingle2(type: Test) {
    include '**/*Test.class'
    exclude '**/BugsTest.class'
    exclude '**/DDLPersistenceHDFSTest.class'
    exclude '**/*DUnitTest.class'
    exclude '**/*DUnit.class'
    exclude '**/derbyTesting/**'
  }
  task junit {
    def testClasses = new ArrayList()
    testClasses.addAll(junitSingle1.getCandidateClassFiles().getFiles())
    def single = System.getProperty("junit.single")
    if (single == null || single.length() == 0) {
      testClasses.addAll(junitSingle2.getCandidateClassFiles().getFiles())
    }
    parallelTests(project, testClasses, test, 'junit', 3, test.maxParallelForks)
  }
  task junitReport(type: TestReport) {
    description 'Combines the parallel junit test reports.'
    destinationDir = file("${testResultsBase}/junit/html/${project.name}")
    mustRunAfter junitParallel
  }
  gradle.taskGraph.whenReady({ graph ->
    project.tasks.getByName('junitReport').reportOn project.tasks.withType(Test).matching {
      it.getName().startsWith('junitParallel')
    }
  })
  junit.dependsOn junitParallel, junitReport

  task dunitTest(type:Test) {
    dependsOn "${subprojectBase}product"
    maxParallelForks = Math.max((int)Math.sqrt(Runtime.getRuntime().availableProcessors() + 1) + 1, 2)
    minHeapSize = '512m'
    maxHeapSize = '512m'

    def single = System.getProperty("dunit.single")
    if (single == null || single.length() == 0) {
      include '**/*DUnitTest.class'
      include '**/*DUnit.class'
      exclude '**/pivotal/gemfirexd/wan/**/*DUnit.class'
    } else {
      include single
    }

    workingDir = "${testResultsBase}/dunit"

    binResultsDir = file("${workingDir}/binary/${project.name}")
    reports.html.destination = file("${workingDir}/html/${project.name}")
    reports.junitXml.destination = file(workingDir)

    //I'm hoping this might deal with SOME OOMEs I've seen
    //forkEvery 30
  }
  task dunit {
    def testClasses = dunitTest.getCandidateClassFiles().getFiles()
    parallelTests(project, testClasses, dunitTest, 'dunit', 4, dunitTest.maxParallelForks)
  }
  task dunitReport(type: TestReport) {
    description 'Combines the parallel dunit test reports.'
    destinationDir = file("${testResultsBase}/dunit/html/${project.name}")
    mustRunAfter dunitParallel
  }
  gradle.taskGraph.whenReady({ graph ->
    project.tasks.getByName('dunitReport').reportOn project.tasks.withType(Test).matching {
      it.getName().startsWith('dunitParallel')
    }
  })
  dunit.dependsOn dunitParallel, dunitReport

  task wanTest(type:Test) {
    dependsOn "${subprojectBase}product"
    maxParallelForks = (int)Math.sqrt(Runtime.getRuntime().availableProcessors() + 1)
    minHeapSize = '512m'
    maxHeapSize = '512m'

    def single = System.getProperty("wan.single")
    if (single == null || single.length() == 0) {
      include '**/pivotal/gemfirexd/wan/**/*DUnit.class'
    } else {
      include single
    }

    workingDir = "${testResultsBase}/wan"

    binResultsDir = file("${workingDir}/binary/${project.name}")
    reports.html.destination = file("${workingDir}/html/${project.name}")
    reports.junitXml.destination = file(workingDir)

    // increase the number of JVMs for WAN tests
    systemProperties 'gemfire.DUnitLauncher.NUM_VMS' : '8'
  }
  task wan {
    def wanClasses = wanTest.getCandidateClassFiles().getFiles()
    parallelTests(project, wanClasses, wanTest, 'wan', 1, wanTest.maxParallelForks)
  }
  task wanReport(type: TestReport) {
    description 'Combines the parallel wan test reports.'
    destinationDir = file("${testResultsBase}/wan/html/${project.name}")
    mustRunAfter wanParallel
  }
  gradle.taskGraph.whenReady({ graph ->
    project.tasks.getByName('wanReport').reportOn project.tasks.withType(Test).matching {
      it.getName().startsWith('wanParallel')
    }
  })
  wan.dependsOn wanParallel, wanReport

  task integrationTest(type:Test) {
    dependsOn "${subprojectBase}product"
    maxParallelForks = (2 * Runtime.getRuntime().availableProcessors())

    include '**/*Test.class'
    exclude '**/*DUnitTest.class'
    exclude '**/*DUnit.class'
    useJUnit {
      includeCategories 'com.gemstone.junit.IntegrationTest'
      excludeCategories 'com.gemstone.junit.UnitTest'
      excludeCategories 'com.gemstone.junit.DistributedTest'
    }    

    workingDir = "${testResultsBase}/integration"

    binResultsDir = file("${workingDir}/binary/${project.name}")
    reports.html.destination = file("${workingDir}/html/${project.name}")
    reports.junitXml.destination = file(workingDir)
  }

  // apply common test configuration
  gradle.taskGraph.whenReady({ graph ->
    tasks.withType(Test).each { test ->
      test.configure {

        jvmArgs = ['-XX:+HeapDumpOnOutOfMemoryError', '-XX:MaxPermSize=128M', '-XX:+UseParNewGC', '-XX:+UseConcMarkSweepGC', '-XX:CMSInitiatingOccupancyFraction=50', '-XX:+CMSClassUnloadingEnabled', '-ea']

        testLogging.exceptionFormat = 'full'

        systemProperties 'gemfire.DEFAULT_MAX_OPLOG_SIZE' : '10',
                         'gemfire.disallowMcastDefaults'  : 'true',
                         'java.net.preferIPv4Stack'       : 'true',
                         'jline.terminal'                 : 'scala.tools.jline.UnsupportedTerminal',
                         'store.test.resourceDir'         : "${projectDir}/src/test/resources",
                         'GEMFIREXD'                      : productDir.getAbsolutePath()

        def logLevel = System.getProperty('logLevel')
        if (logLevel != null && logLevel.length() > 0) {
          systemProperties 'gemfire.log-level'            : logLevel,
                           'logLevel'                     : logLevel
        }
        logLevel = System.getProperty('securityLogLevel')
        if (logLevel != null && logLevel.length() > 0) {
          systemProperties 'gemfire.security-log-level'   : logLevel,
                           'securityLogLevel'             : logLevel
        }

        environment 'GEMFIREXD'                           : productDir.getAbsolutePath(),
                    'JUNIT_JAR'                           : sourceSets.test.output.classesDir

        if (rootProject.name == 'snappy-store') {
          def eol = System.getProperty('line.separator')
          beforeTest { desc ->
            def now = new Date().format('yyyy-MM-dd HH:mm:ss.SSS Z')
            def progress = new File(workingDir, "progress.txt")
            def output = new File(workingDir, "output.txt")
            progress << "${now} Starting test ${desc.className} ${desc.name}${eol}"
            output << "${now} STARTING TEST ${desc.className} ${desc.name}${eol}${eol}"
          }
          onOutput { desc, event ->
            def output = new File(workingDir, "output.txt")
            def msg = event.message
            if (event.destination.toString() == 'StdErr') {
              msg = msg.replace("\n", "\n[stderr]  ")
            }
            output << msg
          }
          afterTest { desc, result ->
            def now = new Date().format('yyyy-MM-dd HH:mm:ss.SSS Z')
            def progress = new File(workingDir, "progress.txt")
            def output = new File(workingDir, "output.txt")
            progress << "${now} Completed test ${desc.className} ${desc.name} with result: ${result.resultType}${eol}"
            output << "${eol}${now} COMPLETED TEST ${desc.className} ${desc.name} with result: ${result.resultType}${eol}${eol}"
            result.exceptions.each { t ->
              progress << "  EXCEPTION: ${getStackTrace(t)}${eol}"
              output << "${getStackTrace(t)}${eol}"
            }
          }
        }
      }
    }
  })

  test.dependsOn subprojectBase + 'cleanTestOutput'
  junitParallel.dependsOn subprojectBase + 'cleanTestOutput'
  dunitTest.dependsOn subprojectBase + 'cleanDUnitOutput'
  dunitParallel.dependsOn subprojectBase + 'cleanDUnitOutput'
  wanTest.dependsOn subprojectBase + 'cleanWanOutput'
  wanParallel.dependsOn subprojectBase + 'cleanWanOutput'
  integrationTest.dependsOn subprojectBase + 'cleanIntegrationOutput'
  check.dependsOn.clear()
  check.dependsOn junit, dunit, wan
}

// maven publish tasks
subprojects {

  if (rootProject.name == 'snappy-store') {
    task packageSources(type: Jar, dependsOn: classes) {
      classifier = 'sources'
      from sourceSets.main.allSource
    }
    task packageDocs(type: Jar, dependsOn: javadoc) {
      classifier = 'javadoc'
      from javadoc
    }
    task packageTests(type: Jar, dependsOn: testClasses) {
      description 'Assembles a jar archive of test classes.'
      from sourceSets.test.output.classesDir
      classifier = 'tests'
    }
    artifacts {
      testOutput packageTests
    }
  }
  if (rootProject.hasProperty('enablePublish')) {
    artifacts {
      archives packageDocs, packageSources
    }

    uploadArchives {
      repositories {
        mavenDeployer {
          beforeDeployment { MavenDeployment deployment -> signing.signPom(deployment) }

          repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
            authentication(userName: ossrhUsername, password: ossrhPassword)
          }
          snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots/") {
            authentication(userName: ossrhUsername, password: ossrhPassword)
          }

          pom.project {
            name PRODUCT_NAME
            packaging 'jar'
            // optionally artifactId can be defined here
            description 'SnappyData store based off Pivotal GemFireXD'
            url 'http://www.snappydata.io'

            scm {
              connection 'scm:git:https://github.com/SnappyDataInc/snappy-store.git'
              developerConnection 'scm:git:https://github.com/SnappyDataInc/snappy-store.git'
              url 'https://github.com/SnappyDataInc/snappy-store'
            }

            licenses {
              license {
                name 'The Apache License, Version 2.0'
                url 'http://www.apache.org/licenses/LICENSE-2.0.txt'
              }
            }

            developers {
              developer {
                id 'smenon'
                name 'Sudhir Menon'
                email 'smenon@snappydata.io'
              }
            }
          }
        }
      }
    }
  }
}

task junit {
  dependsOn subprojects.junit
}
task dunit {
  dependsOn "${subprojectBase}gemfirexd-tools:dunit"
}
task wan {
  dependsOn "${subprojectBase}gemfirexd-tools:wan"
}
task integrationTest {
  dependsOn subprojects.integrationTest
}

task combineReports(type: TestReport) {
  description 'Combines the test reports.'
  dependsOn cleanReports
  destinationDir = file("${testResultsBase}/combined-reports")
  mustRunAfter test, junit, dunit, wan, integrationTest
}

gradle.taskGraph.whenReady({ graph ->
  tasks.getByName('combineReports').reportOn rootProject.subprojects.collect{ it.tasks.withType(Test) }.flatten()
})

junit.dependsOn subprojects.junit
check.dependsOn.clear()
check.dependsOn junit, dunit
if (!Boolean.getBoolean('skip.wanTest')) {
  check.dependsOn wan
}
// skip combineReports for top-level builds which has its own combineReports
if (!rootProject.hasProperty('store')) {
  check.dependsOn combineReports
}

task generateSources {
  dependsOn subprojectBase + 'gemfire-jgroups:jgMagic'
  dependsOn subprojectBase + 'gemfire-core:createVersionPropertiesFile'
  dependsOn subprojectBase + 'gemfirexd-core:compileJavacc'
  dependsOn subprojectBase + 'gemfirexd-core:generatePropertiesFiles'
  dependsOn subprojectBase + 'gemfire-core:createVersionPropertiesFile'
  dependsOn subprojectBase + 'gemfirexd-shared:createVersionPropertiesFile'
  dependsOn subprojectBase + 'gemfirexd-core:doSplit'
  dependsOn subprojectBase + 'gemfirexd-client:generatePropertiesFiles'
  dependsOn subprojectBase + 'gemfirexd-tools:compileJavacc'
  dependsOn subprojectBase + 'gemfirexd-tools:generatePropertiesFiles'
}

def includeJar(def jarFile) {
  def jarName = jarFile.getName()
  return jarName.contains('jetty') || jarName.contains('spring') ||
    jarName.contains('hadoop') || jarName.contains('protobuf') ||
    jarName.contains('jersey') || jarName.contains('jetty') ||
    jarName.contains('jsr305') || jarName.contains('pxf') ||
    jarName.contains('jline')
}

// pack the entire GemFireXD product tree
task product(dependsOn: [ subprojectBase + 'gemfirexd-client:jar',
    subprojectBase + 'gemfirexd-core:shadowJar',
    subprojectBase + 'gemfirexd-tools:jar' ]) << {

  delete productDir

  def sharedProject = project(subprojectBase + 'gemfirexd-shared')
  def clientProject = project(subprojectBase + 'gemfirexd-client')
  def gemcoreProject = project(subprojectBase + 'gemfire-core')
  def coreProject = project(subprojectBase + 'gemfirexd-core')
  def toolsProject = project(subprojectBase + 'gemfirexd-tools')

  def gcmDir = System.getProperty('GCMDIR', '/gcm')

  def extraJars = (gemcoreProject.configurations.provided - gemcoreProject.configurations.runtime +
        coreProject.configurations.provided - coreProject.configurations.runtime +
        toolsProject.configurations.provided - toolsProject.configurations.runtime).filter {
    includeJar(it)
  }
  // first copy the product and dependent jars
  copy {
    from(clientProject.jar.destinationDir) {
      include clientProject.jar.archiveName
    }
    from(coreProject.jar.destinationDir) {
      include coreProject.shadowJar.archiveName
    }
    from(toolsProject.jar.destinationDir) {
      include toolsProject.jar.archiveName
    }
    from extraJars
    into "${productDir}/lib"
  }

  // next the scripts
  copy {
    from(toolsProject.projectDir.getAbsolutePath() + '/bin') {
      include 'gfxd'
      include 'color'
      include 'appdirector/gemfirexd*'
      include 'dataextractor'
      include 'dataextractloader'
      include 'gfxd-completion.bash'
      if (osName.isWindows()) {
        include 'gfxd.bat'
        include 'dataextractor.bat'
        include 'dataextractloader.bat'
      }
    }
    into "${productDir}/bin"
    filter { line ->
      line.replaceAll('__VERSION__', version)
    }
    fileMode 0755
  }

  // the native JNI library
  if (osName.isLinux()) {
    copy {
      from coreProject.projectDir.getAbsolutePath() + '/lib'
      into "${productDir}/lib"
    }
  }

  // examples, javadocs, vsd
  copy {
    from(project(subprojectBase + 'gemfirexd-core').projectDir.getAbsolutePath() + '/../examples') {
      exclude 'src/main/java/mapreduce/README.txt'
      exclude 'src/main/java/mapreduce/pom.xml'
    }
    from(coreProject.projectDir.getAbsolutePath()) {
      include 'src/main/java/com/pivotal/gemfirexd/callbacks/DBSynchronizer.java'
      include 'src/main/java/com/pivotal/gemfirexd/callbacks/AsyncEventHelper.java'
    }
    into "${productDir}/examples"
  }
  copy {
    from(project(subprojectBase + 'gemfirexd-core').projectDir.getAbsolutePath() + '/../examples') {
      include 'src/main/java/mapreduce/README.txt'
      include 'src/main/java/mapreduce/pom.xml'
    }
    into "${productDir}/examples"
    filter { line ->
      line.replaceAll('__VERSION__', version)
    }
  }
  copy {
    from (project(subprojectBase + 'gemfirexd-core').projectDir.getAbsolutePath() + '/../quickstart')
    into "${productDir}/quickstart"
  }
  copy {
    from "${gcmDir}/where/vsd/70/vsd"
    into "${productDir}/tools/vsd"
  }
  if (rootProject.hasProperty('docs')) {
    copy {
      from sharedProject.javadoc.destinationDir
      from coreProject.javadoc.destinationDir
      into "${productDir}/docs/japi"
    }
  }
  copy {
    from(rootDir.getAbsolutePath() + '/release/images') {
      include 'GemFireXD_190x81.png'
    }
    from(rootDir.getAbsolutePath() + '/release/docfiles') {
      include 'copyright.html'
      include 'support.html'
      include 'DocIndex.css'
      include 'gfxd-index.html'
    }
    into "${productDir}/docs"
    rename 'gfxd-index.html', 'index.html'
  }

  copy {
    from (project(subprojectBase +  'gemfire-tests').projectDir.getAbsolutePath() + '/src/main/java') {
      include '**/*.bt'
      include '**/*.conf'
      include '**/*.inc'
      include '**/*.sql'
      include '**/*.prop'
      include '**/*.spec'
      include '**/*.gold'
      include '**/*.properties'
      include '**/*.keystore'
      include '**/*.ts'
      include '**/*.pl'
      include 'bin/testManagerLogWriter.sh'
      include 'hydratest/hydracheck/*.sh'
      include 'bin/scaleperf/*'
    }
    from (project(subprojectBase +  'gemfirexd-tests').projectDir.getAbsolutePath() + '/src/main/java') {
      include '**/*.bt'
      include '**/*.conf'
      include '**/*.inc'
      include '**/*.sql'
      include '**/*.prop'
      include '**/*.spec'
      include '**/*.gold'
      include '**/*.properties'
      include '**/*.keystore'
      include '**/*.ts'
      include '**/*.pl'
    }
    into (project(subprojectBase + 'gemfirexd-tests').buildDir.getAbsolutePath() + '/classes/main')
  }
}
if (rootProject.hasProperty('docs')) {
  product.dependsOn subprojectBase + 'gemfirexd-shared:javadoc',
                    subprojectBase + 'gemfirexd-core:javadoc'
}

task cleanAll {
  dependsOn clean, subprojects.clean
}
task buildAll {
  dependsOn subprojects.assemble, subprojects.testClasses, product
  mustRunAfter cleanAll
}
check.mustRunAfter buildAll
task precheckin {
  if (project.hasProperty('gfxd')) {
    dependsOn cleanAll, buildAll, check
  }
}
